type: install
version: 1.5
id: kubernetes
baseUrl: https://raw.githubusercontent.com/jelastic-jps/kubernetes/v1.16.3
description:
  text: /text/description-kube.md
  short: Kubernetes cluster with automated scaling & cost efficient pay-per-use pricing for running cloud-native microservices.
categories:
  - apps/clusters
  - apps/dev-and-admin-tools

logo: /images/k8s-logo.png
name: Kubernetes Cluster
targetRegions:
  type: vz7

ssl: true
onBeforeInit: /scripts/beforeinit.js
onBeforeInstall: /scripts/beforeinstall.js

nodes: definedInOnBeforeInstall

skipNodeEmails: true

globals:
    dashboardUrl:  https://${env.domain}/kubernetes-dashboard/

onInstall:
  - block-masters-scaling
  - init-main-master
  - forEach(node:nodes.k8sm):
      if (!${@node.ismaster}):
        init-slave-master:
          id: ${@node.id}
          ip: ${@node.intIP}

  - connect-workers: cp
  - setup-overlay
  - if ('${settings.ingress-controller}' == 'Nginx'):
      - setGlobals:
          ingress-dir: nginx
      - install-nginx
  - elif ('${settings.ingress-controller}' == 'HAProxy'):
      - setGlobals:
          ingress-dir: haproxy
      - install-haproxy
  - else:
      - setGlobals:
          ingress-dir: traefik
      - install-traefik
  - install-components
  - install-helm-master
  - forEach(node:nodes.k8sm):
      if (!${@node.ismaster}):
        install-helm-slave:
          id: ${@node.id}
  - install-node-problem-detector
  - generate-admin-token
  - connect-storage
  - deploy
  - remove-attr

  - if (${settings.api:true}):
      - setup-remote-api: true

  - if (${settings.monitoring:false}):
        - install-monitoring

  - if (${settings.jaeger:false}):
        - install-jaeger

  - if ('${env.protocol}' == 'http'):
      - api: env.control.AddEndpoint
        nodeId: ${nodes.cp.master.id}
        privatePort: 30777
        protocol: TCP
        name: Dashboard Self-Signed HTTPS
      - setGlobals:
          dashboardUrl: https://node${nodes.cp.master.id}-${env.domain}:${response.object.publicPort}/

  - setGlobals:
        default_success: |
             Enter [Kubernetes dashboard](${globals.dashboardUrl}) ${globals.default_api:} using the Access Token:

             ```${globals.token}```
             Press **Open in Browser** to view a default web page of your application.
             To bind a custom domain name with your Kubernetes cluster please refer to the steps described in Jelastic [documentation](https://docs.jelastic.com/custom-domains).
  - check-health

onAfterScaleOut[cp]:
  - get-ids: event.response.nodes
  - connect-workers: ${globals.ids}

onBeforeScaleIn[cp]:
  forEach(event.response.nodes):
    removeWorker:
      workerHostname: node${@i.id}-${env.domain}

onBeforeClone: stopEvent

actions:
  block-masters-scaling:
    env.control.ApplyNodeGroupData[k8sm]:
      data:
        validation:
          minCount: ${nodes.k8sm.length}
          maxCount: ${nodes.k8sm.length}

  init-main-master:
    - if (${nodes.mbl.length:0}):
        cmd[mbl]: |-
          sed -i '/^<\/mappings>.*/i \\t<pair frontend_port="6443" backend_port="6443" description="CPlane balancing" option="tcp-check" params="check fall 3 rise 2">' /etc/haproxy/tcpmaps/mappings.xml
          sed -i 's/^bind :::80/#bind :::80/g' /etc/haproxy/haproxy.cfg
          sed -i '/^daemon$/a stats socket /var/run/haproxy.sock mode 660 level admin' /etc/haproxy/haproxy.cfg
          sed -i '/^daemon$/a stats timeout 2m' /etc/haproxy/haproxy.cfg
          echo '${nodes.k8sm.master.intIP}' > /etc/haproxy/hosts
          jem balancer rebuildCommon
        user: root
    - cmd[${nodes.k8sm.master.id}]: |-
        systemctl daemon-reload > /dev/null 2>&1
        entryPoint=$((( ${nodes.mbl.length:0} > 0 )) && echo mbl || echo k8sm)
        sed -i "s/^controlPlaneEndpoint:.*/controlPlaneEndpoint: \"${entryPoint}.${env.domain}:6443\"/g" /etc/kubernetes/custom-kubeadm.yaml
        kubeadm init --config /etc/kubernetes/custom-kubeadm.yaml --upload-certs --ignore-preflight-errors=swap,numcpu | tee /var/log/kubeadm-init.log
    - configure-master: ${nodes.k8sm.master.id}
    - cmd[${nodes.k8sm.master.id}]: sed -n '/kubeadm join/,/^$/{/./p}' /var/log/kubeadm-init.log | sed ':a;N;$!ba;s/\\\n//g' | grep 'control-plane'
    - setGlobals:
        master_join_cmd: ${response.out}
    - if (${settings.api:true}):
        - setGlobals:
            default_api: or [Remote API Endpoint](${env.protocol}://${env.domain}/api/)

  init-slave-master:
    - cmd[${this.id}]: |-
        systemctl daemon-reload > /dev/null 2>&1
        ${globals.master_join_cmd} --ignore-preflight-errors=swap,numcpu > /dev/null 2>&1
    - configure-master: ${this.id}
    - cmd[mbl]: |-
        echo '${this.ip}' >> /etc/haproxy/hosts
        jem balancer rebuildCommon
      user: root

  configure-master:
    cmd[${this}]: |-
      mkdir -p $HOME/.kube
      cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
      chown root:root $HOME/.kube/config
      wget -qO- https://github.com/derailed/k9s/releases/download/v0.17.7/k9s_Linux_x86_64.tar.gz | tar xz -C /usr/bin k9s
      wget -qO- https://github.com/derailed/popeye/releases/download/v0.7.1/popeye_Linux_x86_64.tar.gz | tar xz -C /usr/bin popeye
      wget -nv https://github.com/wercker/stern/releases/download/1.11.0/stern_linux_amd64 -O /usr/bin/stern
      chmod +x /usr/bin/stern
      /usr/bin/stern --completion=bash > /etc/bash_completion.d/stern.bash
      kubectx_version=0.8.0
      wget -qO- https://github.com/ahmetb/kubectx/archive/v${kubectx_version}.tar.gz | tar xz --strip-components=1 -C /usr/bin kubectx-${kubectx_version}/kubectx kubectx-${kubectx_version}/kubens
      wget -qO- https://github.com/ahmetb/kubectx/archive/v${kubectx_version}.tar.gz | tar xz --strip-components=2 -C /etc/bash_completion.d kubectx-${kubectx_version}/completion/kubens.bash kubectx-${kubectx_version}/completion/kubectx.bash
      wget -nv https://github.com/weaveworks/weave/releases/download/v2.5.2/weave -O /usr/bin/weave
      chmod +x /usr/bin/weave
      wget -nv ${baseUrl}/scripts/wait-deployment.sh -O /usr/local/sbin/wait-deployment.sh
      chmod +x /usr/local/sbin/wait-deployment.sh
    configure-all-post: ${this}

  connect-workers:
    - cmd[${nodes.k8sm.master.id}]: |-
        token_age=$(expr $(date +%s) - $(stat /var/log/kubeadm-init.log -c %Y))
        [ ${token_age} -lt $((20*60*60)) ] && { sed -n '/kubeadm join/,/^$/{/./p}' /var/log/kubeadm-init.log | sed ':a;N;$!ba;s/\\\n//g' | grep -v 'control-plane'; } || { kubeadm token create --print-join-command; }
    - setGlobals:
        worker_join_cmd: ${response.out}
    - cmd[${this}]: |-
        rm -f /etc/machine-id
        systemd-machine-id-setup
        systemctl daemon-reload > /dev/null 2>&1
        local_ip=$(/usr/sbin/ip route get 1.2.3.4 | grep -v 'cache' | uniq | head -n 1 | sed -n 's/.* src \([^ ]*\).*/\1/p')
        [ -n "${local_ip}" ] && local_ip_route="10.244.0.0/15 dev venet0 src ${local_ip}"
        [ -n "${local_ip_route}" ] && /usr/sbin/ip route add ${local_ip_route} && echo "${local_ip_route}" >> /etc/sysconfig/network-scripts/route-venet0
        ${globals.worker_join_cmd} --ignore-preflight-errors=swap,numcpu > /dev/null 2>&1
        sleep 5
    - configure-all-post: ${this}

  configure-all-post:
    cmd[${this}]: |-
      iptables -I INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT
      service iptables save
      systemctl start kube-config.service
      systemctl enable docker.service
      systemctl enable kubelet.service
      systemctl enable kube-config.service

  setup-overlay:
    cmd[${nodes.k8sm.master.id}]: |-
      kubectl apply -f ${baseUrl}/addons/weave-pack.yaml

  install-nginx:
     cmd[${nodes.k8sm.master.id}]: |-
      kubectl apply -f ${baseUrl}/addons/nginx/mandatory.yaml
      kubectl apply -f ${baseUrl}/addons/nginx/cloud-generic.yaml

  install-haproxy:
     cmd[${nodes.k8sm.master.id}]: |-
      kubectl apply -f ${baseUrl}/addons/haproxy/haproxy-deployment.yaml

  install-traefik:
     cmd[${nodes.k8sm.master.id}]: |-
      kubectl apply -f ${baseUrl}/addons/traefik/traefik-rbac.yaml
      kubectl apply -f ${baseUrl}/addons/traefik/traefik-ds.yaml
      kubectl apply -f ${baseUrl}/addons/traefik/traefik-ui.yaml

  install-components:
    - cmd[${nodes.k8sm.master.id}]: |-
        kubectl create -f ${baseUrl}/addons/metrics-server/aggregated-metrics-reader.yaml
        kubectl create -f ${baseUrl}/addons/metrics-server/auth-delegator.yaml
        kubectl create -f ${baseUrl}/addons/metrics-server/auth-reader.yaml
        kubectl create -f ${baseUrl}/addons/metrics-server/metrics-apiservice.yaml
        kubectl create -f ${baseUrl}/addons/metrics-server/metrics-server-deployment.yaml
        kubectl create -f ${baseUrl}/addons/metrics-server/metrics-server-service.yaml
        kubectl create -f ${baseUrl}/addons/metrics-server/resource-reader.yaml
        kubectl create -f ${baseUrl}/addons/admin-account.yaml
        wait-deployment.sh metrics-server kube-system 1 720

    - if ('${settings.dashboard}' == 'version1'):
        cmd[${nodes.k8sm.master.id}]: |-
           kubectl create -f ${baseUrl}/addons/kubernetes-dashboard.yaml
           kubectl create -f ${baseUrl}/addons/ingress/${globals.ingress-dir}/dashboard-ingress.yaml

    - if ('${settings.dashboard}' == 'version2'):
        cmd[${nodes.k8sm.master.id}]: |-
           kubectl apply -f ${baseUrl}/addons/kubernetes-dashboard-beta.yaml
           kubectl apply -f ${baseUrl}/addons/ingress/${globals.ingress-dir}/dashboard-ingress-beta.yaml

  install-helm-master:
    cmd[${nodes.k8sm.master.id}]: |-
      wget https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get -O /usr/local/sbin/helm-install.sh
      chmod +x /usr/local/sbin/helm-install.sh
      /usr/local/sbin/helm-install.sh --version v2.16.3
      kubectl create serviceaccount --namespace kube-system tiller
      kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
      helm init --upgrade --service-account tiller
      helm repo update
      wait-deployment.sh tiller-deploy kube-system 1 720

  install-helm-slave:
    cmd[${this.id}]: |-
      wget https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get -O /usr/local/sbin/helm-install.sh
      chmod +x /usr/local/sbin/helm-install.sh
      /usr/local/sbin/helm-install.sh --version v2.16.3
      helm init --client-only
      helm repo update

  generate-admin-token:
    - cmd[${nodes.k8sm.master.id}]: kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep fulladmin | awk '{print $1}')  | grep 'token:' | sed -e's/token:\| //g'
    - setGlobals:
        token: ${response.out}

  deploy:
    - if ('${settings.deploy}' == 'cc'):
        cmd[${nodes.k8sm.master.id}]: |-
          kubectl apply -f ${baseUrl}/addons/helloworld.yaml
          kubectl apply -f ${baseUrl}/addons/ingress/${globals.ingress-dir}/helloworld-ingress.yaml
    - if ('${settings.deploy}' == 'cmd'):
        cmd[${nodes.k8sm.master.id}]: |-
          ${settings.cmd}
          if [ '${settings.ingress-controller}' == "Nginx" ]; then kubectl delete ingress/open-liberty-traefik ingress/open-liberty-haproxy || true; fi
          if [ '${settings.ingress-controller}' == "HAProxy" ]; then kubectl delete ingress/open-liberty-traefik ingress/open-liberty-nginx || true; fi
          if [ '${settings.ingress-controller}' == "Traefik" ]; then kubectl delete ingress/open-liberty-haproxy ingress/open-liberty-nginx || true; fi
    - if ('${settings.deploy}' == 'yml'):
        cmd[${nodes.k8sm.master.id}]: kubectl apply -f ${settings.yml}

  connect-storage:
    if (${settings.storage:false}):
      cmd[${nodes.k8sm.master.id}]: helm install stable/nfs-client-provisioner --set nfs.server=${nodes.storage.master.address} --set nfs.path=/data --set nfs.mountOptions='{soft,proto=tcp}' --set replicaCount=3 --set storageClass.defaultClass=true --set storageClass.allowVolumeExpansion=true --set storageClass.name=jelastic-dynamic-volume

  removeWorker:
    cmd[${nodes.k8sm.master.id}]: |-
      /usr/bin/kubectl drain ${this.workerHostname} --ignore-daemonsets --delete-local-data || exit 8;
      /usr/bin/kubectl delete node ${this.workerHostname} || exit 9;

  remove-attr:
    cmd[*]: |-
      chattr -i -a /root/.bash_*
    user: root

  init-manifest-globals:
  - cmd[${nodes.k8sm.master.id}]: |-
      /usr/bin/kubectl get daemonset traefik-ingress-controller -n kube-system &>/dev/null && echo "traefik" ||:
      /usr/bin/kubectl get deployment nginx-ingress-controller -n ingress-nginx &>/dev/null && echo "nginx" ||:
      /usr/bin/kubectl get daemonset nginx-ingress-controller -n ingress-nginx &>/dev/null && echo "nginx" ||:
      /usr/bin/kubectl get daemonset haproxy-ingress -n ingress-controller &>/dev/null && echo "haproxy" ||:
  - setGlobals:
      ingress-dir: ${response.out}

  setup-remote-api:
  - log: '${this}'
  - cmd[${nodes.k8sm.master.id}]: |-
      action=$([ "${this}" == "true" ] && echo "apply" || echo "delete")
      kubectl $action -f ${baseUrl}/addons/ingress/${globals.ingress-dir}/api-ingress.yaml
  - if (${settings.api:true}):
      - setGlobals:
          default_api: or [Remote API Endpoint](${env.protocol}://${env.domain}/api/)

  install-monitoring:
  - if (!${settings.storage:false}):
      return:
        type: warning
        message: Monitoring components require Storage installed!
  - cmd[${nodes.k8sm.master.id}]: kubectl get secret --namespace kubernetes-monitoring monitoring-grafana &>/dev/null && echo "true" || echo "false"
  - setGlobals:
      monitoring_installed: ${response.out}
  - if ('${globals.monitoring_installed}' == 'false'):
      - init-manifest-globals
      - cmd[${nodes.k8sm.master.id}]: |-
          helm repo update
          helm install --name monitoring-prometheus --namespace kubernetes-monitoring stable/prometheus --set server.prefixURL=/prometheus --set server.baseURL=/prometheus
          wait-deployment.sh monitoring-prometheus-server kubernetes-monitoring 1 720
          helm fetch stable/grafana --untar
          for dash_name in "kubernetes-prometeus-dashboard" "kubernetes-rchakra3-dashboard" "kubernetes-vanniekerk-dashboard"; do
            wget "${baseUrl}/addons/monitoring/${dash_name}.json" -O "grafana/dashboards/${dash_name}.json"
          done
          helm install --name monitoring-grafana --namespace kubernetes-monitoring --set 'grafana\.ini'.server.root_url=${env.url}grafana -f ${baseUrl}/addons/monitoring/jelastic-values.yaml grafana/.
          wait-deployment.sh monitoring-grafana kubernetes-monitoring 1 720
          grafana_secret=$(kubectl get secret --namespace kubernetes-monitoring monitoring-grafana -o jsonpath='{.data.admin-password}' | base64 --decode ; echo)
          [ "${settings.ingress-controller}" == "HAProxy" ] && crypt_option="-1" || crypt_option="-apr1"
          kubectl create secret generic monitoring-prometheus --from-literal=auth="admin:$(openssl passwd ${crypt_option} ${grafana_secret})" --namespace=kubernetes-monitoring
          kubectl create -f ${baseUrl}/addons/monitoring/${globals.ingress-dir}/prometheus-ingress.yaml
          kubectl create -f ${baseUrl}/addons/monitoring/${globals.ingress-dir}/alert-ingress.yaml
          kubectl create -f ${baseUrl}/addons/monitoring/${globals.ingress-dir}/grafana-ingress.yaml
          for i in {1..10}; do
            sleep 10
            echo "Attempt ${i} of Grafana dashboard parameters setting"
            curl -X POST -f -d "user=admin&password=${grafana_secret}" -c grafana/grafana-jar.txt "http://${env.domain}/grafana/login" || contunue
            dash_id=$(curl -sb grafana/grafana-jar.txt 'http://${env.domain}/grafana/api/search?mode=tree&query=Jelastic' | grep -Po '"id":(\d+)' | awk -F ':' '{print $2}')
            [ "${dash_id}" = "" ] && continue
            curl -X POST -f -b grafana/grafana-jar.txt "http://${env.domain}/grafana/api/user/stars/dashboard/${dash_id}" || continue
            curl -X PUT -f -H 'Content-Type: application/json' -b grafana/grafana-jar.txt -d "{\"homeDashboardId\":${dash_id}}" "http://${env.domain}/grafana/api/org/preferences" && break || continue
          done
  - cmd[${nodes.k8sm.master.id}]: kubectl get secret --namespace kubernetes-monitoring monitoring-grafana -o jsonpath='{.data.admin-password}' | base64 --decode
  - setGlobals:
      grafana_secret: ${response.out}
  - setGlobals:
      monitoring_success: |
          Enter [Prometheus dashboard](${env.url}prometheus/), [Prometheus AlertManager](${env.url}prometheus-alert/)
          and [Grafana dashboard](${env.url}grafana/), using login "admin" and password:

          ```${globals.grafana_secret}```
  - if ('${globals.monitoring_installed}' == 'true'):
      return:
        type: info
        message: ${globals.monitoring_success}
  - if (!${settings.monitoring:false}):
      message.email.send:
            to: "${user.email}"
            subject: Monitoring Tools Successfully Installed in ${env.name}
            body: |-
              Monitoring Tools installed in <b>${env.name}</b> Kubernetes Cluster: <br>
              Prometheus Dashboard - ${env.url}prometheus/<br>
              Prometheus AlertManager - ${env.url}prometheus-alert/ <br>
              Grafana Dashboard - ${env.url}grafana/ <br>
              Credentials - admin / ${globals.grafana_secret}
      return:
        type: info
        message: ${globals.monitoring_success}

  install-jaeger:
  - if (!${settings.storage:false}):
      return:
        type: warning
        message: Jaeger components require Storage installed!
  - cmd[${nodes.k8sm.master.id}]: kubectl get secret observability-jaeger-plain --namespace=observability &>/dev/null && echo "true" || echo "false"
  - setGlobals:
      jaeger_installed: ${response.out}
  - if ('${globals.jaeger_installed}' == 'false'):
      - init-manifest-globals
      - cmd[${nodes.k8sm.master.id}]: |-
          kubectl create namespace observability
          kubectl create -f ${baseUrl}/addons/jaeger/jaegertracing.io_jaegers_crd.yaml
          kubectl create -f ${baseUrl}/addons/jaeger/service_account.yaml
          kubectl create -f ${baseUrl}/addons/jaeger/role.yaml
          kubectl create -f ${baseUrl}/addons/jaeger/role_binding.yaml
          kubectl create -f ${baseUrl}/addons/jaeger/operator.yaml
          [ "${settings.ingress-controller}" == "HAProxy" ] && crypt_option="-1" || crypt_option="-apr1"
          jaeger_secret=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1)
          kubectl create secret generic observability-jaeger-plain --from-literal=auth="${jaeger_secret}" --namespace=observability
          kubectl create secret generic observability-jaeger --from-literal=auth="admin:$(openssl passwd ${crypt_option} ${jaeger_secret})" --namespace=observability
          kubectl apply -f ${baseUrl}/addons/jaeger/jelastic-jaeger.yaml
          kubectl apply -f ${baseUrl}/addons/ingress/${globals.ingress-dir}/jaeger-ingress.yaml
          wait-deployment.sh jaeger-operator observability 1 720
          wait-deployment.sh jaeger observability 1 720
  - cmd[${nodes.k8sm.master.id}]: kubectl get secret --namespace=observability observability-jaeger-plain -o jsonpath='{.data.auth}' | base64 --decode
  - setGlobals:
      jaeger_secret: ${response.out}
  - setGlobals:
      jaeger_success: |
          Enter [Jaeger dashboard](${env.url}jaeger/), using login "admin" and password:

          ```${globals.jaeger_secret}```
  - if ('${globals.jaeger_installed}' == 'true'):
      return:
        type: info
        message: ${globals.jaeger_success}
  - if (!${settings.jaeger:false}):
      message.email.send:
          to: "${user.email}"
          subject: Jaeger Tracing Tools Successfully Installed in ${env.name}
          body: |-
              Jaeger Tracing Tools installed in <b>${env.name}</b> Kubernetes Cluster: <br>
              Jaeger Dashboard - ${env.url}jaeger/ <br>
              Credentials - admin / ${globals.jaeger_secret}
      return:
        type: info
        message: ${globals.jaeger_success}

  get-ids:
    - setGlobals:
        ids: ''
        sep: ''
    - forEach(${this}):
        add-id: ${@i.id}

  add-id:
    setGlobals:
      ids: ${globals.ids:}${globals.sep:}${this}
      sep: ','

  install-node-problem-detector:
     - cmd[${nodes.k8sm.master.id}]: helm install stable/node-problem-detector --name node-problem-detector

  check-health:
      cmd[${nodes.k8sm.master.id}]: mkdir -p /var/log/kubernetes && curl -s ${baseUrl}/scripts/check-install.sh | bash -s -- -i=${settings.ingress-controller} -app=${settings.deploy} -m=${settings.monitoring:false} -r=${settings.api} -s=${settings.storage} -j=${settings.jaeger:false} -d=${env.domain}  &> /var/log/kubernetes/k8s-health-check.log || echo "*Warning! Some cluster components have not yet been initialized, and it may take some time for pods to start. If you encounter problems with your cluster, please check K8s logs in /var/log/kubernetes on master node and contact support.*"
      setGlobals:
         check_message: ${response.out}

addons:

  - id: conf-k8s-addon
    type: update
    permanent: true
    baseUrl: https://raw.githubusercontent.com/jelastic-jps/kubernetes/v1.16.3
    name: Kubernetes Cluster Configuration
    description: Configure remote API access and install complementary tools
    logo: /images/k8s-logo.png
    settings:
      fields:
        - type: displayfield
          caption: Useful info
          hideLabel: true
          markup: Access and manage the cluster remotely via API
        - type: checkbox
          name: api
          caption: Remote API access is enabled
        - type: string
          name: ingress-controller
          inputType: hidden
        - type: string
          name: storage
          inputType: hidden

    buttons:
      - caption: Remote API
        settings: main
        action: addon-remote-api
        loadingText: Updating...
        confirmText: Are you sure?
        successText: Remote API Access was successfully updated!
      - caption: Monitoring
        action: install-monitoring
        confirmText: Monitoring tools will be installed if missing. Continue?
      - caption: Jaeger
        action: install-jaeger
        confirmText: Jaeger will be installed if missing. Continue?

    actions:
      addon-remote-api:
      - log: '${this.api}'
      - init-manifest-globals
      - setup-remote-api: ${this.api}
      - if (${this.api:true}):
          - setGlobals:
              apiStatusMessage: enabled at ${env.url}api
      - else:
          - setGlobals:
              apiStatusMessage: disabled
      - message.email.send:
          to: "${user.email}"
          subject: Remote API Access Successfully Updated in ${env.name}
          body: Remote API has been ${globals.apiStatusMessage}


  - id: upgrade-k8s-addon
    type: update
    permanent: true
    baseUrl: https://raw.githubusercontent.com/jelastic-jps/kubernetes/v1.16.3
    name: Kubernetes Cluster Upgrade
    description: Upgrade Kubernetes cluster to a newer version
    logo: /images/k8s-logo.png

    buttons:
      - caption: Start Cluster Upgrade
        action: addon-upgrade
        loadingText: Updating...
        confirmText: Do you want to upgrade Kubernetes Cluster?
        successText: Kubernetes Cluster has been successfully upgraded!

    actions:
      addon-upgrade:
      - forEach(node:env.nodes):
          if ('${@node.nodeGroup}' == 'cp' || '${@node.nodeGroup}' == 'k8sm'):
            if ('${nodes.k8sm.master.version}' != '${@node.version}'):
              return:
                type: warning
                message: Cluster components have different Kubernetes version! Please contact support before upgrade.
      - script: |
          function compareVersions(a, b) {
            a = a.replace("v", "").split("."); b = b.replace("v", "").split(".");
            for (var i = 0, l = Math.max(a.length, b.length), x, y; i < l; i++) {x = parseInt(a[i], 10) || 0; y = parseInt(b[i], 10) || 0; if (x != y) return x > y ? 1 : -1 }
            return 0;
          }

          var envName = "${env.envName}", nodeId = "${nodes.k8sm.master.id}";
          var resp = jelastic.env.control.GetNodeInfo(envName, session, nodeId);
          if (resp.result != 0) return resp;
          var version = resp.node.version;
          var image = resp.node.name;
          resp = jelastic.env.control.GetContainerNodeTags(envName, session, nodeId);
          if (resp.result != 0) return resp;

          var tags = resp.object;
          tags.sort(compareVersions);
          var upgrades = [];
          var check_version = version;
          var major_version = version.substr(0, version.lastIndexOf("."));

          for (var i = 0; i < tags.length; i++) {
            var major_tag = tags[i].substr(0, tags[i].lastIndexOf("."));
            if (compareVersions(major_tag, major_version) > 0) {
              check_version = tags[i];
              upgrades.push(check_version);
              major_version = major_tag;
            }
          }

          var last_version = tags.pop();
          if (compareVersions(last_version, check_version) > 0) upgrades.push(last_version);
          var message = "Current version " + version + " is the latest. No upgrades are available.";
          if (upgrades.length) {
            upgrades.sort(compareVersions);
            var next = upgrades.shift();
            var baseUrl = "${baseUrl}".split("/"); baseUrl.pop(); baseUrl = baseUrl.join("/");
            var url = baseUrl+"/"+next+"/addons/upgrade.jps";
            var huc = new java.net.URL(url).openConnection();
            huc.setRequestMethod("HEAD");
            var code = huc.getResponseCode();
            if (code == 200){
              return {result:0, onAfterReturn:{execUpgrade:{current:version, next:next, avail:upgrades.join(", "), jps: url}}};
            } else {
              message = "The next version is " + next + ". However, automated upgrade procedure is not available yet. Please check it later, or contact support team if upgrade is required urgently.";
              return {result:"info", message:message};
            }
          } else {
            return {result:"info", message:message};
          }

      execUpgrade:
        jps: ${this.jps}
        envName: ${env.envName}
        version: ${this.next}
        avail: ${this.avail}
        upgradeScript: |
          jelastic.marketplace.jps.Install({ envName: envName, session: session, jps: jps, settings: { version: version, avail: avail } });
          return { result: 0 };
        script: |
          var envName = '${env.envName}',
          scriptName = envName + '-k8s-upgrade';
          jelastic.dev.scripting.DeleteScript(scriptName);
          resp = jelastic.dev.scripting.CreateScript(scriptName, "js", upgradeScript);
          if (resp.result != 0) return resp;
          java.lang.Thread.sleep(1000);
          jelastic.dev.scripting.Build(scriptName);
          resp = jelastic.utils.scheduler.AddTask({ script: scriptName, trigger: "once_delay:1000", description: "Upgrade Kubernetes", params: { envName: envName, jps: jps, version: version, avail: avail } });
          if (resp.result != 0) return resp;
          java.lang.Thread.sleep(3000);
          return { type: "info", message: "Kubernetes Cluster upgrade to " + version + " started" };

success: |
  ${globals.default_success:}
  ${globals.monitoring_success:}
  ${globals.jaeger_success:}
  ${globals.check_message:}
